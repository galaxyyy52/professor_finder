






 


Deming Chen 


Administrative TitlesAbel Bliss Professor of Engineering

Professor
(217) 244-3922
dchen@illinois.edu
250 Coordinated Science Lab



For More Information
Professor Chen's Home Page

Education
Ph.D. in Computer Science,
University of California at Los Angeles,
2005
B.S. Computer Science,	
University of Pittsburgh, 
Pittsburgh, Pennsylvania,
1995

BiographyDr. Deming Chen obtained his BS in computer science from University of Pittsburgh, Pennsylvania in 1995, and his MS and PhD in computer science from University of California at Los Angeles in 2001 and 2005 respectively. He worked as a software engineer between 1995-1999 and 2001-2002. He joined the ECE department of University of Illinois at Urbana-Champaign in 2005 and has been a full professor in the same department since 2015. He is a research professor in the Coordinated Science Laboratory and an affiliate professor in the CS department. His current research interests include reconfigurable computing, cloud computing, system-level and high-level synthesis, machine learning and IoT, and hardware security. He has given more than 130 invited talks sharing these research results worldwide.Dr. Chen has been a technical committee member for a series of top conferences and symposia on EDA, FPGA, low-power design, and embedded systems design. He has also served as General or TPC Chair, Track Chair, Session Chair, Panelist, Panel Organizer, or Moderator for many of these conferences. He has been an associated editor for IEEE TCAD, ACM TODAES, IEEE TVLSI, ACM TRETS, IEEE TCAS-I and TCAS-II, IEEE Design & Test, IET Cyber-Physical Systems, JCSC, and JOLPE. He obtained the Achievement Award for Excellent Teamwork from Aplus Design Technologies in 2001, the Arnold O. Beckman Research Award from UIUC in 2007, the NSF CAREER Award in 2008, ten Best Paper Awards, a TCFPGA Hall-of-Fame paper award, and a few Best Poster Awards. He also received the ACM SIGDA Outstanding New Faculty Award in 2010, IBM Faculty Award in 2014 and 2015, and Google Faculty Award in 2020. In 2017 and 2019 respectively, he led a team to win the First Place Winner Award of DAC International System Design Contest. He is the Donald Willett Faculty Scholar and the Abel Bliss Professor of the Grainger College of Engineering, an IEEE Fellow, an ACM Distinguished Speaker, and the Editor-in-Chief of ACM Transactions on Reconfigurable Technology and Systems (TRETS). He is the Director of the AMD-Xilinx Center of Excellence and the Hybrid Cloud Thrust Co-lead in the IBM-Illinois Discovery Accelerator Institute. He has given a series of Keynote or Plenary speeches at various conferences. He is also included in the List of Teachers Ranked as Excellent in 2008 and 2017 from UIUC. Dr. Chen was involved in several startup companies. He implemented his published algorithm on CPLD technology mapping when he was a software engineer in Aplus Design Technologies, Inc. in 2001, and the software was exclusively licensed by Altera (now part of Intel) and distributed to many customers of Altera worldwide. He is one of the inventors of the xPilot High Level Synthesis package developed at UCLA, which was licensed to AutoESL Design Technologies, Inc. Aplus was acquired by Magma in 2003, and AutoESL was acquired by Xilinx in 2011. In 2016, he co-founded a new startup, Inspirit IoT, Inc.
Professional Highlights
NEW! PyLog: PyLog is a high-level, algorithm-centric Python-based programming and synthesis flow for FPGA. PyLog is powered by a set of compiler optimization passes and a type inference system to generate high-quality design. PyLog takes in Python functions, generates PyLog intermediate representation (PyLog IR), performs several optimization passes, including pragma insertion, design space exploration, and memory customization, etc., and creates the complete FPGA system design. PyLog also has a runtime that allows users to run the PyLog code directly on the target FPGA platform without any extra code development. Available since 2021. Download: https://github.com/hst10/pylog
NEW! HELLO: HELLO is a new DNA variant calling tool, where we use novel DNN (Deep Neural Network) architectures and customized variant inference functions that account for the underlying nature of sequencing data. Our method allows vastly smaller DNNs to outperform the Inception-v3 architecture used in DeepVariant for indel and substitution-type variant calls. Our improved accuracy and problem-specific customization of DNN models could enable more accurate pipelines and further method development in the field. Available since 2021. Download: https://github.com/anands-repo/hello 
NEW! ScaleHLS: ScaleHLS is a next-generation HLS compilation flow, on top of a multi-level compiler infrastructure called MLIR. ScaleHLS is able to represent and optimize HLS designs at multiple levels of abstraction and provides an HLS-dedicated transform and analysis library to solve the optimization problems at the suitable representation levels. We also build an automated DSE engine to explore the multi-dimensional design space efficiently. ScaleHLS shows amazing quality-of-results – up to 768.1× better on computation kernel level programs and up to 3825.0× better on neural network models, compared to the unoptimized designs. Available since 2021. Download: https://github.com/hanchenye/scalehls
NEW! WinoCNN: WinoCNN combines systolic array and fast Winograd algorithm for CNN acceleration. This system supports flexible convolution kernel sizes without sacrificing DSP efficiency through various algorithmic, architecture and on-chip memory subsystem designs and optimizations. Overall, our accelerator delivers high throughput and state-of-the-art DSP efficiency compared to previous accelerator implementations. Available since 2021. Download: https://github.com/xliu0709/WinoCNN
NEW! TwinDNN: TwinDNN system pairs a high-accuracy heavy-duty network with a low-latency light-weight (e.g., highly compressed) network using a hierarchical inference logic that will infer high-accuracy network when the prediction of low-latency network is not considered confident. TwinDNN can recover up to 94% of accuracy drop caused by extreme network compression, with more than 90% speedup. Available since 2021. Download: https://github.com/jeonghm9764/TwinDNN
NEW! ThunderGP: ThunderGP enables data scientists to enjoy the performance of FPGA-based graph processing without compromising programmability. To our best knowledge and experiments, this is the fastest graph processing framework on HLS-based FPGAs. Available since 2021.
Download: https://github.com/Xtra-Computing/ThunderGP
NEW! FracBNN: FracBNN is a binary neural network, which achieves MobileNetV2-level accuracy by leveraging fractional activations. In the meantime, its input layer is binarized using a novel thermometer encoding with minimal accuracy degradation, which improves the hardware resource efficiency. The paper for FracBNN was a Best Paper Candidate at the ACM/SIGDA International Symposium on Field Programmable Gate Arrays in 2021. Available since 2021. Download: https://github.com/cornell-zhang/FracBNN
NEW! AutoDNNchip: AutoDNNchip is a design flow able to target different accelerator platforms such as FPGA, TPU, GPU, and ASIC. AutoDNNchip can produce either FPGA-based AI accelerators or ASIC AI chip designs and achieve better (up to 3.86× improvement) performance over expert-crafted state-of-the-art AI chip solutions. This provides a valuable framework for producing and evaluating different types of hardware accelerators to find the best or the most suitable ones that can be deployed to various AI applications. Available since 2020. Download: https://github.com/RICE-EIC/AutoDNNchip
SkyNet: SkyNet is a new hardware-efficient DNN model specialized in object detection and tracking. SkyNet was developed based on the SkyNet Design Methodology to facilitate edge AI solutions, and demonstrated in the 56th IEEE/ACM Design Automation Conference System Design Contest (DAC-SDC), a low power object detection challenge for real-life unmanned aerial vehicle (UAV) applications. SkyNet won the First Place Award for both GPU and FPGA tracks of the contest in 2019. Available since 2019.
Download: https://github.com/TomG008/SkyNet
Thanos: This open-source package introduces Thanos, a fast graph partitioning tool which uses the cross-decomposition algorithm that iteratively partitions a graph. It also produces balanced loads of partitions. The algorithm is well suited for parallel GPU programming which leads to fast and high-quality graph partitioning solutions. Experimental results show that we have achieved a 30x speedup and 35% better edge cut reduction compared to the CPU version of the popular graph partitioning tool METIS on average. Download: https://github.com/dannyk0104/thanos

μL2Q: This open-source package introduces an ultra-low loss quantization (μL2Q) method that provides DNN quantization schemes based on comprehensive quantitative data analysis. μL2Q builds the transformation of the original data to a data space with standard normal distribution, and then finds the optimal parameters to minimize the loss of the quantization of a target bitwidth. Our method can deliver consistent accuracy improvements compared to the state-of-the-art quantization solutions with the same compression ratio. Download: https://github.com/microideax/Quantization-caffe
T-DLA: T-DLA (Ternarized Deep Learning Accelerator) is an open-source microprocessor designed specifically for accelerating DNN models trained with ternarized weights. This is the first instruction-based DLA design targeting ternary-quantized weights. T-DLA can deliver up to 0.4TOPS with 2.576W power consumption, showing 873.6x and 5.1x higher performance (fps/W) on ImageNet with Resnet-18 model comparing to Xeon E5-2630 CPU and Nvidia 1080 Ti GPU. 
Download: https://github.com/microideax/T-DLA
DNNBuilder (Open Source): This package provides a novel solution that can automatically convert the Caffe trained DNN to the FPGA RTL level implementation without involving any hardware programming effort. It also provides uniform APIs to the users for their AI recognition task. The developers, without any FPGA programming experience, can deploy their FPGA accelerated deep learning services for both cloud and edge computing, only by providing their trained Caffe models. The paper for DNNBuilder has won the IEEE/ACM William J. McCalla ICCAD Best Paper Award in 2018. Download: https://github.com/IBM/AccDNN

Cloud-DNN (Open Source): A framework that maps DNN (deep neural network) models trained by Caffe to FPGAs in the cloud for inference acceleration. It takes the input *.prototxt DNN description, generates corresponding C++ network description, and then produces the final hardware accelerator IPs through high-level synthesis. The goal of Cloud-DNN is to provide more flexible and user-friendly DNN acceleration on cloud-FPGAs (e.g., AWS F1). Download: https://github.com/microideax/Open-Dnn
DNN IPs: This IP Package includes an open-source IP repository specifically designed for machine learning applications. The IPs include: Standard convolution IPs, Depth-wise separable convolution IPs, Pooling IPs, Bounding box regression IP, and Long-term Recurrent Convolutional Network IP. Each IP is provided with: introduction, interface description, inputs and outputs description, parameter configuration, and resource and performance. The IPs are developed in C/C++. The source code is synthesizable and RTL code can be generated conveniently using Xilinx Vivado HLS. Download: https://github.com/DNN-Accelerators/Open-Source-IPs
RIP (Open Source): This open source project contains three inter-related software packages (fast software modeling, fast hardware modeling and design space exploration, and hardware/software co-design), for the ultimate task of automated hardware/software partitioning targeting either sophisticated SoC designs or computing on heterogeneous systems. The paper for fast hardware modeling and DSE embedded in this package has won the IEEE/ACM William J. McCalla ICCAD Best Paper Award in 2015. Download: https://github.com/UIUC-ChenLab/rip
FCUDA (Open Source): A system-synthesis compiler to map GPU CUDA code to FPGA. Enable a common frontend language for heterogeneous compute platforms where FPGA and GPU co-exist. Low-power FPGA computing with comparable performance as GPU. FCUDA project has produced two Best Paper Awards for the conferences SASP'09 and FCCM'11. Download: http://dchen.ece.illinois.edu/tools.html
H.264 HLS Benchmark (Open Source): Fully synthesizable H.264 Video Decoder code, which can be synthesized into RTL with high-level synthesis for FPGA implementation and achieve real-time decoding. Download: http://dchen.ece.illinois.edu/tools.html
Click for more
Research StatementThe spectacular CMOS technology scaling has created a large design productivity gap due to inherent design complexities and deep submicron issues. Development cost, including both the design cost and manufacturing cost, of integrated circuits has grown significantly given the increasing size of the design team and the lengthy design cycles. Meanwhile, intensive computational demands arising from emerging workloads, such as those in various IoT and deep-learning related domains, require new architecture and hardware designs, novel automated design flows, and efficient accelerator deployments both at the edge and in the cloud. In this context, the research group led by Prof. Chen mainly pursues the following research directions: system-level and high-level design automation, machine learning and cognitive computing, hybrid cloud, hardware/software co-design, and FPGA and GPU computing. The group recently is also pursuing several other research directions, such as computational genomics and hardware system security.
Graduate Research OpportunitiesWe are recruiting. If you are passionate about research, inspired for innovation and impact, determined to pursue a Ph.D. in Computer Engineering, and your research interests match one or more topics as listed in the "RESEARCH INTERESTS" section below, please contact Prof. Chen directly through email and attach your detailed CV.
Undergraduate Research OpportunitiesWe are looking for committed and mature undergrad researchers for the following topics: FPGA and GPU computing, machine learning and hardware acceleration, high-level and system-level synthesis, and security in IoT and smart grid.
Research Interests
GPU optimization and GPU computing
Hardware/software co-design for SoC
Machine learning and hardware acceleration
Reconfigurable computing and FPGAs
Hardware security for smart IoT applications
System-level and high-level synthesis
Click for more

Research Areas
Algorithms and computational complexity
Computer aided design
Computer aided design of integrated circuits
Digital integrated circuits
Fault tolerance and reliability
Hardware verification and testing
Integrated circuit reliability
Logic design and VLSI
Nano-electronics and single electronics
Click for more

Research Topics
Autonomous Systems and Artificial Intelligence
Autonomous vehicular technology, UAVs
Bioelectronics and Bioinformatics
Cognitive computing
Computational science and engineering
Cyberinfrastructures
Cyberphysical systems and internet of things
Cybersecurity and privacy
Data science and analytics
Data/Information Science and Systems
Distributed computing and storage systems
Energy
Genomics
Machine learning
Machine vision
Nanomedicine and bio-nanotechnology
Point-of-care diagnostics
Robotics
Smart grid and energy delivery
Smart infrastructures
Speech, language, and audio processing
Wearable and mobile computing
Click for more
Journal Editorships
Editor-in-Chief, ACM Transactions on Reconfigurable Technology and Systems (TRETS), 2019-2025

Professional Societies
Chair, IEEE CEDA Fellow Evaluation Committee, 2023
Member, ACM SIGDA Outstanding New Faculty Award Committee, 2022
Chair, IEEE CEDA Fellow Evaluation Committee, 2022
Founding Chair, IEEE CEDA Central Illinois Chapter, 2016-2023 

Service on Department Committees
Chair, ECE Graduate Committee, 2020-2022
CE Area Chair, 2015-2017

Service on College Committees
Hybrid Cloud Thrust Co-lead, IBM-Illinois Discovery Accelerator Institute, 2021 - present
Chief Scientist, IBM-Illinois Center for Cognitive Computing Systems Research, 2020 - 2021
Director, AMD/Xilinx Center of Excellence, 2020 - present
Representative of CSL on the College Executive Committee, 2016-2019

Service on Campus Committees
Senator, Faculty Senate, 2014-2016, 2018-2020, 2022-2024

Honors
Distinguished Speaker, Distinguished Speaker Series, ECE, Northwestern University, 2022
Induction of the “FCUDA: Enabling efficient compilation of CUDA kernels onto FPGAs” paper into the TCFPGA Hall of Fame for FPGAs, 2022
Second Place Winner, System Design Contest at IEEE/ACM Design Automation Conference, 2021
Best Paper Award, International Conference on Intelligent Data Engineering and Automated Learning, 2021
ACM SIGDA Distinguished Service Award, 2021
Keynote Speaker, International Conference on Intelligent Data Engineering and Automated Learning (IDEAL), 2021
Distinguished Speaker, Distinguished Speaker Series, Universidad Católica San Pablo, 2021
Google Faculty Award, for supporting machine learning courses, diversity and inclusion, 2020.
Keynote Speaker, IEEE International Conference on Field-Programmable Technology, 2020
Distinguished Speaker, Distinguished Speaker Series, ECE, Rice University, 2020
Keynote Speaker, ACM Great Lakes Symposium on VLSI, 2020
Distinguished Speaker, Distinguished Speaker Series, ACM Sacramento Chapter, 2020
Keynote Speaker, ROAD4NN: Research Open Automatic Design for Neural Networks, 2020
Best Paper Award, IEEE International Conference on VLSI Design, 2020
Abel Bliss Professor of Engineering, 2020 - present
Keynote Speaker, Computing Conference, 2019
Editor-in-Chief, ACM Transactions on Reconfigurable Technology and Systems, 2019-2025
IEEE Fellow, 2019
ACM Distinguished Speaker, 2019-2022
First Place Winner, both the FPGA and the GPU categories, System Design Contest at IEEE/ACM Design Automation Conference, 2019
Best Poster Award, Joint Workshop on On-Device Machine Learning & Compact Deep Neural Network Representations (ODML-CDNNR), 2019
Invited Distinguished Speaker, COOL Chips, 2019
Best Paper Award, IEEE/ACM Intl Conf on Computer-Aided Design, 2018
Keynote Speaker, International Conference on Big Data Analytics & Data Mining, 2018
Best Paper Award, IEEE/ACM Intl Workshop on System-Level Interconnect Prediction, 2018
Plenary Speech, IEEE Computer Society Annual Symposium on VLSI, 2018
First Place Winner, Intl Hardware Design Contest, Design Automation Conf, 2017
Keynote paper, Integration, the VLSI Journal, 2017
Recognition of Service Award, ACM, 2016, 2018
Best Paper Award, IEEE/ACM Intl Conf on Computer-Aided Design, 2015
Keynote speech, IEEE International Conference on ASIC, 2015
Donald Biggar Willett Faculty Scholar, College of Engineering, University of Illinois, 2015
Keynote speech, IEEE International Conference on Anti-counterfeiting, Security, and Identification, 2014
IBM Faculty Award, 2014 and 2015
Best Paper Award, IEEE Intl Conf on Hardware/Software Codesign and System
Synthesis, 2013
Best Paper Award, Symp on Application Accelerators in High Performance Computing, 2011 
Best Paper Award, IEEE Intl Symp on Field-Programmable Custom Computing Machines, 2011
ACM SIGDA Outstanding New Faculty Award, 2010
Best Paper Award, IEEE Symp on Application Specific Processors, 2009
Best Paper Award, IEEE/ACM Asia and South Pacific Design Automation Conf, 2009
CAREER Award, National Science Foundation, 2008
Arnold O. Beckman Research Award, UIUC, 2007
Achievement Award for Excellent Teamwork, Aplus Design Technologies, Inc, 2001
Click for more
Teaching Honors
On the List of Teachers Ranked as Excellent by Students, Spring 2008, Fall 2017

Public Service Honors
Founding Chair of IEEE CEDA chapter for Central Illinois (12/1/2016)


Recent Courses TaughtECE 411 - Computer Organization & Design
ECE 462 - Logic Synthesis
ECE 479 - IoT and Cognitive Computing
ECE 498 ICC (ECE 498 IL1, ECE 498 IL2, ECE 498 IL3, ECE 498 IL4) - IoT and Cognitive Computing
ECE 527 - System-On-Chip Design







Related News


Looking up: scaling up high-level synthesis for faster, more efficient chip design


IBM-Illinois connection spurs on collaborative learning, research opportunities


University of Illinois researchers are part of a $15M institute developing real-time artificial intelligence to accelerate discovery in data-driven science


Illinois ECE graduate student receives 2020 Google PhD Fellowship


Chen and Hwu lead Illinois in establishing advanced research cluster with Xilinx


C3SR ushers in new age of computing








